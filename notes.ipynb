{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "# text_source = \"https://github.com/karpathy/char-rnn/raw/master/data/tinyshakespeare/input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " თავდაპირველაღ ღმერთმა შექმნა ცა და მიწა. 2. მიწა იყო უსახო და უდაბური, ბნელი იდო უფსკრულზე და სული ღვთისა იძვროდა წყლებს ზემოთ. 3. თქვა ღმერთმა: იყოს ნათელი! და იქმნა ნათელი. 4. და ნახა ღმერთმა, რომ ნათელი კარგი იყო, და გაჰყარა ღმერთმა ნათელი და ბნელი. 5. ნათელს ღმერთმა უწოდა დღე და ბნელს უწოდა ღამ 4070812 ინმე რამეს მოაკლებს ამ წიგნის წინასწარმეტყველების სიტყვებს, ღმერთი მოაკლებს მას წილს სიცოცხლის ხიდან, წმიდა ქალაქიდან და იქიდან, რაც ჩაწერილია ამ წიგნში. 20. ამის დამმოწმებელი ამბობს: ჰო, მოვალ მალე! ამინ; ჰო, მოდი, უფალო იესო! 21. ჩვენი უფლის, იესო ქრისტეს მადლი ყველა თქვენგანთან. ამინ.  დასასრული.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "# text_source = \"https://github.com/karpathy/char-rnn/raw/master/data/tinyshakespeare/input.txt\"\n",
    "bible = open('data/bible.txt', 'r').read()\n",
    "bible = BeautifulSoup(bible, \"lxml\").text\n",
    "# Remove digits\n",
    "bible = bible[165:-55]\n",
    "# bible = re.sub(r'\\d+.', '', bible)\n",
    "# Remove brackets, \n",
    "bible = re.sub( r'\\([^)]*\\)', '', bible)\n",
    "# Remove symbol ჲ\n",
    "bible = re.sub(r'ჲ', '', bible)\n",
    "bible = re.sub(r'\\*', '', bible)\n",
    "bible = re.sub(r'\\[', '', bible)\n",
    "bible = re.sub(r'\\]', '', bible)\n",
    "# Replace all different types of quotes with \"\n",
    "bible = re.sub(r'[\\u201c\\u201d\\u201e\\u201f\\u2033\\u2036]', '\"', bible)\n",
    "print(bible[:300], len(bible), bible[-300:])\n",
    "text = bible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070812"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " თავდაპირველაღ ღმერთმა შექმნა ცა და მიწა. 2. მიწა იყო უსახო და უდაბური, ბნელი იდო უფსკრულზე და სული ღვთისა იძვროდა წყლებს ზემოთ. 3. თქვა ღმერთმა: იყოს ნათელი! და იქმნა ნათელი. 4. და ნახა ღმერთმა, რომ ნათელი კარგი იყო, და გაჰყარა ღმერთმა ნათელი და ბნელი. 5. ნათელს ღმერთმა უწოდა დღე და ბნელს უწოდა ღამე. იყო საღამო, იყო დილა პირველი დღე. 6. თქვა ღმერთმა: იყოს წყალთა შორის მყარი და გაჰყაროს წყლები. 7. გააჩინა ღმერთმა მყარი და გაჰყარა ერთმანეთისგან წყალი, რომელიც არის მყარს ქვემოთ, და წყალი, რომელიც არის მყარს ზემოთ. და იქმნა ასე. 8. მყარს ღმერთმა უწოდა ცა. იყო საღამო, იყო დილა - მეორე დღე.  9. თქვა ღმერთმა: შეგროვდეს ერთგან ცისქვეშეთის წყალი და გამოჩნდეს ხმელეთი. და იქმნა ასე. 10. ხმელეთს ღმერთმა უწოდა მიწა და შეგროვილ წყალს უწოდა ზღვა. დაინახა ღმერთმა, რომ კარგი იყო. 11 . თქვა ღმერთმა: აღმოაცენოს მიწამ მცენარეული - ბალახი, თესლის მთესველი, ხე ნაყოფიერი, თესლოვანი ნაყოფის მომტანი მიწაზე თავისი გვარისდა მიხედვით. და იქმნა ასე. 12. წარმოშვა მიწამ მცენარეული - ბალახი, თესლის მთესველი თავისი გ\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' !\",-.0123456789:;?აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ',\n",
       " 52,\n",
       " 52,\n",
       " Counter({' ': 577606,\n",
       "          'ა': 508111,\n",
       "          'ი': 360423,\n",
       "          'ე': 293164,\n",
       "          'ს': 216612,\n",
       "          'მ': 198341,\n",
       "          'რ': 167257,\n",
       "          'დ': 161316,\n",
       "          'ნ': 141570,\n",
       "          'ო': 138072,\n",
       "          'ვ': 136167,\n",
       "          'ლ': 132852,\n",
       "          'თ': 114936,\n",
       "          'ბ': 92771,\n",
       "          'უ': 78225,\n",
       "          '.': 74428,\n",
       "          'გ': 70992,\n",
       "          ',': 69405,\n",
       "          'ხ': 62049,\n",
       "          'ც': 52705,\n",
       "          'შ': 51601,\n",
       "          'ყ': 34266,\n",
       "          'კ': 33652,\n",
       "          'ქ': 33259,\n",
       "          'წ': 29784,\n",
       "          'ფ': 25684,\n",
       "          'ღ': 24709,\n",
       "          'ტ': 23270,\n",
       "          'ზ': 18245,\n",
       "          'ჩ': 17185,\n",
       "          '1': 16238,\n",
       "          'ძ': 15938,\n",
       "          '2': 11625,\n",
       "          'პ': 10694,\n",
       "          ':': 9018,\n",
       "          '3': 7468,\n",
       "          ';': 6084,\n",
       "          'ჭ': 5573,\n",
       "          '4': 5458,\n",
       "          'ჰ': 5194,\n",
       "          '-': 4962,\n",
       "          'ჯ': 4861,\n",
       "          '5': 4530,\n",
       "          '6': 4002,\n",
       "          '7': 3680,\n",
       "          '8': 3465,\n",
       "          '9': 3308,\n",
       "          '?': 3272,\n",
       "          '0': 3171,\n",
       "          '!': 2018,\n",
       "          'ჟ': 1228,\n",
       "          '\"': 368}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "''.join(chars), len(chars), vocab_size, Counter(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([27, 42, 32], 'ცად')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda x: ''.join([itos[i] for i in x])\n",
    "\n",
    "encode(\"იყო\"), decode(encode(\"ცად\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4070812]) tensor(0) tensor(51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 'cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.min(), data.max()), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(data) * 0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# block_size = 256\n",
    "\n",
    "# train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) -> tensor(26)\n",
      "tensor([ 0, 26]) -> tensor(19)\n",
      "tensor([ 0, 26, 19]) -> tensor(24)\n",
      "tensor([ 0, 26, 19, 24]) -> tensor(22)\n",
      "tensor([ 0, 26, 19, 24, 22]) -> tensor(19)\n",
      "tensor([ 0, 26, 19, 24, 22, 19]) -> tensor(33)\n",
      "tensor([ 0, 26, 19, 24, 22, 19, 33]) -> tensor(27)\n",
      "tensor([ 0, 26, 19, 24, 22, 19, 33, 27]) -> tensor(35)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:8]\n",
    "y = train_data[1:8+1]\n",
    "for t in range(8):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(context, \"->\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 256]) torch.Size([64, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "max_iters = 5000\n",
    "eval_interval = 500\n",
    "learning_rate = 3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters=200\n",
    "n_embed = 384 \n",
    "n_heads = 6\n",
    "n_layer = 6\n",
    "dropout = 0.1\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    # print(ix, ix.shape, ix.min(), ix.max(), ix.dtype)\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\")\n",
    "print(xb.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context = torch.zeros((1,1), device=device, dtype=torch.long)\n",
    "# print(decode(m.generate(context, 100).tolist()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(m: nn.Module):\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'valid']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(eval_iters):\n",
    "            xb, yb = get_batch('valid')\n",
    "            _, loss = m(xb, yb)\n",
    "            losses[i] = loss\n",
    "        out[split] = f\"Mean: {losses.mean().item():.3f}, Var: {losses.var().item():.3f}\"\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(1337)\n",
    "# B,T,C = 4,8,32 # batch, time, channel\n",
    "# x = torch.randn(B,T,C)\n",
    "\n",
    "# # Single head of SA\n",
    "# # Emit q, and v\n",
    "# head_size = 16\n",
    "# key = nn.Linear(C, head_size, bias=False)\n",
    "# query = nn.Linear(C, head_size, bias=False)\n",
    "# value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "# # Each token emits 16 values (q, k) pairs (head size)\n",
    "\n",
    "# k = key(x)\n",
    "# print(\"k = \", k.var().item())\n",
    "\n",
    "# k = k / (C ** .5) # B,T,HeadSize\n",
    "# q = query(x) # B,T,HeadSize\n",
    "# v = value(x)\n",
    "\n",
    "# print(\"K=\",k.var().item(), '1/hs^2 =',head_size ** -.5)\n",
    "\n",
    "# # wei = torch.zeros((T,T)) # this is made from q dot v \n",
    "# wei = q @ k.permute(0,2,1) # (B,T,H) @ (B,H,T) -> (B,T,T)\n",
    "# print(q.var(), k.var(), wei.var())\n",
    "\n",
    "# tril = torch.tril(torch.ones(T,T))\n",
    "# wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "# wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "# out = wei @ v\n",
    "# # out.shape, out\n",
    "# out.shape, x.var(), out.var(), k.var(), q.var(), v.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single head torch.Size([64, 256, 384]) torch.Size([64, 256, 64]) 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi head torch.Size([64, 256, 384]) torch.Size([64, 256, 384]) 64\n"
     ]
    }
   ],
   "source": [
    "from torch import Tensor\n",
    "# batch_size = 32 * 4\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embed, head_size, bias=False)\n",
    "        self.register_buffer(\n",
    "            'tril', torch.tril(torch.ones(block_size, block_size))\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x) # B,T,H\n",
    "        q = self.query(x)\n",
    "        v = self.value(x)\n",
    "        wei: Tensor = q @ k.permute(0,2,1) * C ** -0.5 # B,T,T\n",
    "        wei.masked_fill_(self.tril[:T,:T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        return wei @ v\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads: int, n_embed: int):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_heads\n",
    "        self.head_size = head_size\n",
    "        self.n_heads = n_heads\n",
    "        self.heads = nn.ModuleList([Head(head_size=head_size) for _ in range(n_heads)])\n",
    "        self.proj = nn.Linear(n_embed, n_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # self.linear = nn.Linear(n_heads * head_size, n_embed, bias=False)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = torch.concat([h(x) for h in self.heads], dim=-1)\n",
    "        x = self.proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "head_size = n_embed // n_heads\n",
    "h = Head(head_size=head_size)\n",
    "x = torch.randn(batch_size, block_size, n_embed)\n",
    "out = h(x)\n",
    "print(\"Single head\", x.shape, out.shape, head_size)\n",
    "\n",
    "h = MultiHeadAttention(n_heads=4, n_embed=n_embed)\n",
    "x = torch.randn(batch_size, block_size, n_embed)\n",
    "out = h(x)\n",
    "print(\"Multi head\", x.shape, out.shape, head_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm1d torch.Size([64, 256]) torch.Size([64, 256]) 64\n",
      "tensor(0.8527, grad_fn=<VarBackward0>) tensor(0.0648, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0000, grad_fn=<VarBackward0>) tensor(-7.4506e-09, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BatchNorm1d(nn.Module):\n",
    "    def __init__(self, n_embed):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.gamma = nn.Parameter(torch.ones(n_embed))\n",
    "        self.beta = nn.Parameter(torch.zeros(n_embed))\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # print(x[:,0].var(), x[:,0].shape)\n",
    "        xhat = (x - x.mean(dim=0, keepdim=True)) / (x.var(dim=0, keepdim=True) + self.eps) ** .5\n",
    "        xhat = xhat * self.gamma + self.beta\n",
    "        # print(xhat[:,0].var(), xhat[:,0].shape)\n",
    "        return xhat \n",
    "    \n",
    "bn = BatchNorm1d(block_size)\n",
    "x = torch.randn(batch_size, block_size)\n",
    "out = bn(x)\n",
    "print(\"BatchNorm1d\", x.shape, out.shape, head_size)\n",
    "print(out[0].var(), out[0].mean())\n",
    "print(out[:,0].var(), out[:,0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embed) -> None:\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embed, 4 * n_embed),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_embed * 4, n_embed),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0690, grad_fn=<VarBackward0>), torch.Size([256, 384]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embed, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embed // n_head\n",
    "        self.ln1 = nn.LayerNorm(n_embed)\n",
    "        self.ln2 = nn.LayerNorm(n_embed)\n",
    "        self.sa = MultiHeadAttention(n_heads=n_head, n_embed=n_embed)\n",
    "        self.ffwd = FeedForward(n_embed=n_embed)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "b = Block(n_embed=n_embed, n_head=n_heads)\n",
    "x = torch.randn(32, block_size, n_embed)\n",
    "x = b(x)[0]\n",
    "x.var(), x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [11:47<00:00,  7.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ანი ტალახაძებისა; ამიტომ ქადაგმიერება შორს მყოფნი დავითის მორჩილნი ჰყავდათ დადიმულნი და უკუნისამდენი ისრაელის წინამძღოლით. 7. გვყავდა შენი სახლი, გახდა, მაგრამ ვერაფერს შევა ჰყავდა ცისკენ, რადგან არ იცოდა შენს ძმას და არ იგულადო. გაწყდნენ შენს გულს და სიკვდილს განსდებულს, რადგან უზენაესის სიძე გამარჯვება მკერდზე. იმ დროს გაუშვა ცისკარი, დაწვა ნაღველი და მასხრის კერპება, რაც აბზია, შენს კერპთათვის არ იცოდი, როგორ შეამთხვა ეს ხალხიც. 23. მაგრამ არის ქერუბიმები, სწორი აღსავლენი და სადაც მანადისი სხური ზლიანი გ\n",
      "ანი ტალახაძებისა; ამიტომ ქადაგმიერება შორს მყოფნი დავითის მორჩილნი ჰყავდათ დადიმულნი და უკუნისამდენი ისრაელის წინამძღოლით. 7. გვყავდა შენი სახლი, გახდა, მაგრამ ვერაფერს შევა ჰყავდა ცისკენ, რადგან არ იცოდა შენს ძმას და არ იგულადო. გაწყდნენ შენს გულს და სიკვდილს განსდებულს, რადგან უზენაესის სიძე გამარჯვება მკერდზე. იმ დროს გაუშვა ცისკარი, დაწვა ნაღველი და მასხრის კერპება, რაც აბზია, შენს კერპთათვის არ იცოდი, როგორ შეამთხვა ეს ხალხიც. 23. მაგრამ არის ქერუბიმები, სწორი აღსავლენი და სადაც მანადისი სხური ზლიანი გ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 \n",
    "                 vocab_size: int,\n",
    "                 n_embed: int) -> None:\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, n_embed\n",
    "        )\n",
    "        self.position_embedding_table = nn.Embedding(\n",
    "            block_size, n_embed\n",
    "        )\n",
    "        # # self.sa_head = Head(n_embed)\n",
    "        # self.multi_sa = MultiHeadAttention(\n",
    "        #     n_heads=4,\n",
    "        #     head_size=n_embed // 4,\n",
    "        # ) # 4 heads, each using 8 dim qkv vectors, and later combine into 32 output vec\n",
    "        # self.ffwd = FeedForward(n_embed=n_embed)\n",
    "        self.blocks = nn.Sequential(\n",
    "            *[Block(n_embed, n_head=4) for _ in range(n_layer)],\n",
    "            # BatchNorm1d(n_embed),\n",
    "            nn.LayerNorm(n_embed),\n",
    "        )\n",
    "        self.lm_head = nn.Linear(\n",
    "            n_embed, vocab_size\n",
    "        )\n",
    "    def forward(self, idx: torch.Tensor, targets = None): \n",
    "        B,T = idx.shape\n",
    "        pos_emb = self.position_embedding_table(\n",
    "            torch.arange(T, device=device)\n",
    "        ) # [T,C]\n",
    "        # print_tensor(\"pos_emb\", pos_emb)\n",
    "        tok_emb = self.embedding(idx) # [B,T,C]\n",
    "        # print_tensor(\"tok_emb\", tok_emb)\n",
    "        x = pos_emb + tok_emb # [B,T, n_embed]\n",
    "        # print_tensor(\"x\", x)\n",
    "        # x = self.sa_head(x)\n",
    "        # x = self.multi_sa(x) # [B,T, n_embed]\n",
    "\n",
    "        # x = self.ffwd(x)\n",
    "        # for b in self.blocks:\n",
    "        x = self.blocks(x)\n",
    "            \n",
    "        # print_tensor(\"x (sa)\", x)\n",
    "        logits = self.lm_head(x) # [B,T,VocabSize]\n",
    "        # print_tensor(\"logits\", logits)\n",
    "        B,T,C = logits.size()\n",
    "        # wei = torch.tril(torch.ones(T,T))\n",
    "        # wei = torch.masked_fill(wei == 0, float('-inf'))\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None \n",
    "        else:\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(B*T,C), targets.view(B*T),\n",
    "            )\n",
    "            return logits, loss\n",
    "        return logits, loss\n",
    "        # return logits\n",
    "    def generate(self, \n",
    "                idx, # [B, T]\n",
    "                max_new_tokens: int):\n",
    "        idx = idx.to(device)\n",
    "        for i in range(max_new_tokens):\n",
    "            # print(idx.shape, idx[:,-block_size:].shape, block_size)\n",
    "            logits, loss = self(idx[:,-block_size:]) \n",
    "            logits: torch.Tensor = logits # [B,T,C]\n",
    "            logits = logits[:,-1,:] # [B,C]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_tokens = torch.multinomial(\n",
    "                probs, num_samples=1,\n",
    "            )\n",
    "            idx = torch.cat([idx, next_tokens], dim=1)\n",
    "        # print(idx, idx.shape)\n",
    "        return idx.cpu()\n",
    "\n",
    "m = BigramLanguageModel(\n",
    "    vocab_size=vocab_size, n_embed=n_embed\n",
    ")\n",
    "m.to(device)\n",
    "opt = torch.optim.AdamW(\n",
    "    m.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "for step in tqdm(range(1000 * 5), file=sys.stdout):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss  = m(xb, yb)\n",
    "    loss: torch.Tensor = loss\n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if step % 500 == 0:\n",
    "        sys.stdout = open('stdout.txt', \"a\")\n",
    "        print(\"STEP:\", step, \"Loss\", estimate_loss(m))\n",
    "        s = decode(m.generate(torch.zeros((1,1)).long(), 120)[0].tolist())\n",
    "        print(s)\n",
    "        sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decode(\n",
    "    m.generate(\n",
    "        torch.tensor([encode('ანი ტალახაძე')], device=device, dtype=torch.long),\n",
    "        120\\\n",
    "    )[0].tolist()\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), 'models/bible-georgian-6layer-384dim-5k.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigramLanguageModel(\n",
       "  (embedding): Embedding(52, 384)\n",
       "  (position_embedding_table): Embedding(256, 384)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Block(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (query): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (value): Linear(in_features=384, out_features=96, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=52, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = BigramLanguageModel(\n",
    "    vocab_size=vocab_size, n_embed=n_embed\n",
    ")\n",
    "m2.load_state_dict(torch.load('models/bible-georgian-6layer-384dim-5k.pt'))\n",
    "m2.eval()\n",
    "m2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1. უწმინდური ანი ტალახაძე და დააბრკოლებ მეფეს ტბორზე, სამუშაოდ რომ დაარწმუნეს, აშენება მეფეები.  \n",
      "12. წავიდნენ ხეზერის ძეთა ტბორზე. \n",
      "13. დაიბარის ტბობიდან თითქოს დამზადებიდან მისი მტრის ძალისკენ გაძარცვავს და მკის წყალობით ამოგვიზკად იქნება. \n",
      "14. როცა ეს ქვეყანა, ეკეთება წარწერაცხმარტება ესუროს თვალს იმ გზაზე, რომელიც ესენი მათ ხორჭას, ასევე თვის სამოგენებღა და მეორე დღეს, სამოსელის მოქცეულისგან. \n",
      "15. სამარადჟამოდ დამიბრუნდა აქაბი ნეემიას ძე, დადგა ისრაელის სახლს მახლობლად. ამიტომ ასე ამბობს ყველა ხალხი, ისრაელის წიაღში იცის\n"
     ]
    }
   ],
   "source": [
    "out = decode(\n",
    "    m2.generate(\n",
    "        torch.tensor([encode('1. უბადრუკი ანი ტალახაძე ')], device=device, dtype=torch.long),\n",
    "        500\n",
    "    )[0].tolist()\n",
    ")\n",
    "# print(out)\n",
    "import re\n",
    "# Place newline before numbering 1,2,3\n",
    "out = str(re.sub(r'(\\d+)', r'\\n\\1', out))\n",
    "print(out, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decode(\n",
    "    m.generate(\n",
    "        torch.tensor([encode('ანი ტალახაძე')], device=device, dtype=torch.long),\n",
    "        500\n",
    "    )[0].tolist()\n",
    ")\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
